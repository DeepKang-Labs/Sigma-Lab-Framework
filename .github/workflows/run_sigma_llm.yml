name: Execute Sigma-LLM (CI-safe, one-shot autodiscover)

on:
  workflow_dispatch:
    inputs:
      prompt:
        description: "Prompt one-shot pour Sigma-LLM"
        required: false
        default: "Diagnostic quotidien : état réseau & marché."
      model_name:
        description: "Modèle HF (ex: gpt2, meta-llama/Meta-Llama-3-8B-Instruct, etc.)"
        required: false
        default: "gpt2"
  schedule:
    - cron: "21 4 * * *"  # chaque jour à 04:21 UTC

permissions:
  contents: read

concurrency:
  group: sigma-llm-${{ github.ref }}
  cancel-in-progress: false

jobs:
  run:
    runs-on: ubuntu-latest

    env:
      SIGMA_CONFIGS_DIR: configs
      SIGMA_STATE_DIR: state
      SIGMA_REPORTS_DIR: reports
      SIGMA_OUTPUTS_DIR: outputs

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip wheel setuptools
          pip install --index-url https://download.pytorch.org/whl/cpu torch
          pip install "transformers>=4.42" "accelerate>=0.33" "tqdm" "numpy" "matplotlib" \
                      "prometheus-client" "faiss-cpu" "sentence-transformers"

      - name: Resolve inputs → $GITHUB_ENV
        shell: bash
        run: |
          PROMPT='${{ github.event.inputs.prompt }}'
          if [ -z "$PROMPT" ]; then
            PROMPT='Diagnostic quotidien : état réseau & marché.'
          fi
          {
            echo 'SIGMA_PROMPT<<EOF'
            echo "$PROMPT"
            echo 'EOF'
          } >> "$GITHUB_ENV"

          MODEL='${{ github.event.inputs.model_name }}'
          if [ -z "$MODEL" ]; then MODEL='gpt2'; fi
          echo "SIGMA_LLM_MODEL=$MODEL" >> "$GITHUB_ENV"

      - name: Ensure defaults (configs/state/reports + package init)
        shell: bash
        run: |
          mkdir -p "$SIGMA_CONFIGS_DIR" "$SIGMA_STATE_DIR" "$SIGMA_REPORTS_DIR" "$SIGMA_OUTPUTS_DIR"
          mkdir -p sigma/core
          [ -f sigma/__init__.py ] || echo "" > sigma/__init__.py
          [ -f sigma/core/__init__.py ] || echo "" > sigma/core/__init__.py

          python - <<'PY'
          import os, json, time, pathlib
          CFG = pathlib.Path(os.getenv("SIGMA_CONFIGS_DIR","configs"))
          ST  = pathlib.Path(os.getenv("SIGMA_STATE_DIR","state"))
          RP  = pathlib.Path(os.getenv("SIGMA_REPORTS_DIR","reports"))
          CFG.mkdir(parents=True, exist_ok=True)
          ST.mkdir(parents=True, exist_ok=True)
          RP.mkdir(parents=True, exist_ok=True)

          params_path = CFG / "sigma_params.json"
          if not params_path.exists():
              json.dump({
                  "alpha": 0.315, "beta": 0.0, "gamma": 0.006, "lambda": 0.195, "mu": 0.205,
                  "theta": [0.52, 0.47, 0.41, 0.50],
                  "W": [
                    [1.00, 0.42, 0.31, 0.55],
                    [0.42, 1.00, 0.48, 0.63],
                    [0.31, 0.48, 1.00, 0.58],
                    [0.55, 0.63, 0.58, 1.00]
                  ],
                  "nu": 0.35,
                  "seuil_veto": 0.08,
                  "subjectivity_decay": 0.002,
                  "O_weights": [0.40, 0.25, 0.20, 0.15],
                  "homeostasis": {
                    "temp":  { "min": 0.60, "max": 1.20, "target_entropy": 0.55, "k": 0.15 },
                    "top_p": { "min": 0.70, "max": 0.98, "target_entropy": 0.55, "k": 0.20 }
                  },
                  "semantic_index": {
                    "max_items": 2000,
                    "min_similarity_to_store": 0.15
                  },
                  "conversation_memory": { "max_turns": 100 },
                  "meta": {
                    "source": "DeepSigma_Optimal_Regim_v1.0",
                    "timestamp": "2025-11-03T00:00:00Z",
                    "description": "Configuration v3.1: ajout subjectivity_decay, O_weights, homeostasis, index sémantique, mémoire conv.",
                    "validated_by": "verify_invariants.yml"
                  }
              }, open(params_path,"w"), indent=2, ensure_ascii=False)

          metrics_path = ST / "last_metrics.json"
          if not metrics_path.exists():
              json.dump({
                  "sigma_percentage": 0.0,
                  "final_C": [0.55, 0.48, 0.52, 0.50],
                  "final_dC": [0.0, 0.0, 0.0, 0.0],
                  "rhoA": 2.35,
                  "dt": 0.1,
                  "timestamp": int(time.time())
              }, open(metrics_path,"w"), indent=2, ensure_ascii=False)
          PY

      - name: Execute Sigma-LLM (CI-safe, one-shot autodiscover)
        id: exec_sigma
        env:
          PYTHONPATH: ${{ github.workspace }}
          SIGMA_PROMPT: ${{ env.SIGMA_PROMPT }}
          SIGMA_LLM_MODEL: ${{ env.SIGMA_LLM_MODEL }}
        shell: bash
        run: |
          python - <<'PY'
          import os, importlib.util, json, sys, pathlib, time
          ROOT = pathlib.Path(".")
          patterns = ["sigma_llm_complete.py", "sigmacomplettllm.py", "sigma_llm*.py", "SigmaLLM*.py"]
          found = []
          for patt in patterns:
              found += [str(p) for p in ROOT.glob(patt)]
          if not found:
              print("::error::Aucun fichier Sigma-LLM trouvé.")
              sys.exit(2)
          script = sorted(found)[0]
          print(f"Using Sigma-LLM script: {script}")
          spec = importlib.util.spec_from_file_location("sigma_llm_mod", script)
          mod  = importlib.util.module_from_spec(spec)
          spec.loader.exec_module(mod)

          prompt = os.getenv("SIGMA_PROMPT", "Diagnostic quotidien : état réseau & marché.")
          model  = os.getenv("SIGMA_LLM_MODEL", "gpt2")

          if not hasattr(mod, "SigmaLLM"):
              print("::error::Classe SigmaLLM introuvable dans le script.")
              sys.exit(3)

          agent = mod.SigmaLLM(model_name=model)
          text  = agent.generate(f"Human: {prompt}\nAI:")

          RP = os.getenv("SIGMA_REPORTS_DIR","reports")
          pathlib.Path(RP).mkdir(parents=True, exist_ok=True)
          ci_report = {
              "ts": int(time.time()),
              "prompt": prompt,
              "model": model,
              "output_preview": text[-1000:]
          }
          with open(f"{RP}/sigma_llm_ci_report.json","w") as f:
              json.dump(ci_report, f, indent=2, ensure_ascii=False)
          PY

      - name: Pretty-print report to job summary
        if: always()
        shell: bash
        run: |
          echo "### Sigma-LLM CI Report" >> "$GITHUB_STEP_SUMMARY"
          if [ -f reports/sigma_llm_ci_report.json ]; then
            echo '```json' >> "$GITHUB_STEP_SUMMARY"
            python -c "import json; print(json.dumps(json.load(open('reports/sigma_llm_ci_report.json')), indent=2, ensure_ascii=False))" >> "$GITHUB_STEP_SUMMARY"
            echo '```' >> "$GITHUB_STEP_SUMMARY"
          else
            echo "_Aucun rapport généré (étapes précédentes échouées)._ " >> "$GITHUB_STEP_SUMMARY"
          fi

      - name: Upload Sigma-LLM report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: sigma_llm_reports_${{ github.run_id }}_${{ github.run_number }}
          path: |
            reports/sigma_llm_ci_report.json
            reports/sigma_llm_last_report.json
          if-no-files-found: warn
          retention-days: 14
